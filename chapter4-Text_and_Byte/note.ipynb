{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'cafe'\n",
      "cafe[0] : 99\n",
      "cafe[1] : 97\n",
      "cafe[2] : 102\n",
      "cafe[3] : 101\n",
      "\n",
      "bytearray(b'cafe')\n",
      "cafe[0] : 99\n",
      "cafe[1] : 97\n",
      "cafe[2] : 102\n",
      "cafe[3] : 101\n",
      "\n",
      "bytearray(b'c')\n"
     ]
    }
   ],
   "source": [
    "cafe = bytes('cafe', encoding='utf-8')\n",
    "print(cafe)\n",
    "\n",
    "for i,b in enumerate(cafe) : \n",
    "    print(f\"cafe[{i}] : {b}\")\n",
    "    \n",
    "cafe_arr = bytearray('cafe', encoding='utf-8')\n",
    "print(\"\\n\",cafe_arr, sep = '')\n",
    "\n",
    "for i,b in enumerate(cafe_arr) : \n",
    "    print(f\"cafe[{i}] : {b}\")\n",
    "    \n",
    "    \n",
    "# bytearray[:1]은 bytearray를 반환한다.\n",
    "print(\"\\n\", cafe_arr[:1], sep = '')\n",
    "\n",
    "# s[0] == s[:1] 이 참이 되는 경우는 str이 유일하다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'\\xfe\\xff\\xff\\xff\\x00\\x00\\x01\\x00\\x02\\x00'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bytes는 형변환을 지원한다.\n",
    "\n",
    "import array\n",
    "nums = array.array('h', [-2,-1,0,1,2])\n",
    "octets = bytes(nums)\n",
    "octets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Codec "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "utf_8\tb'\\xec\\x82\\xac\\xea\\xb3\\xbc'\n",
      "utf_16\tb'\\xff\\xfe\\xac\\xc0\\xfc\\xac'\n",
      "cp949\tb'\\xbb\\xe7\\xb0\\xfa'\n"
     ]
    }
   ],
   "source": [
    "# 어떤 codec을 사용하냐에 따라 인코딩이 달라진다.\n",
    "\n",
    "for codec in ['utf_8', 'utf_16', 'cp949'] :\n",
    "    print(codec, \"사과\".encode(codec), sep = '\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 파일을 작성할 때 작성한 codec과 읽을 때 사용한 codec이 다르면\n",
    "#### 에러를 발생하거나 문자가 깨질 수 있다.\n",
    "#### 따라서 codec을 미리 통일할 필요가 있다. (특히 여러 사람과 작업하게 된다면)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'utf-8' codec can't decode byte 0xbe in position 0: invalid start byte\n",
      "안녕하세요.\n"
     ]
    }
   ],
   "source": [
    "with open(\"text.txt\", 'w', encoding = 'cp949') as f :\n",
    "    f.write(\"안녕하세요.\")\n",
    "\n",
    "try :\n",
    "    f = open(\"text.txt\", 'r', encoding = 'utf-8').read()\n",
    "except Exception as e : \n",
    "    print(e)\n",
    "    f = open(\"text.txt\", 'r', encoding = 'cp949').read()\n",
    "    \n",
    "print(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sys와 locale 에서 default codec을 확인할 수 있다.\n",
    "\n",
    "#### locale은 현재 코드 작성 환경의 codec을 보여준다. \n",
    "#### sys 은 표준입출력의 codec을 보여준다.\n",
    "#### sys.~.isatty() 은 입출력이 콘솔(터미널) 에서 작동하는지 여부를 알려준다.\n",
    "\n",
    "#### 출력을 보면 현재 필자의 코드 작성 환경이 주피터 노트북으로 리다이렉션 됬으므로 isatty() 가 False로 나온다.\n",
    "####   리다이렉션 : 표준입출력을 사용자 지정 위치로 우회하는 것을 말한다.\n",
    "#### locale 이 cp949 이므로 my_file도 cp949로 encoding 되었음을 알 수 있다.\n",
    "#### 하지만 sys 상에서는 utf-8을 디폴트로 사용하고 있다.\n",
    "#### 따라서 my_file을 주피터 노트북 환경이 아닌 터미널에서 실행하여 파일을 읽어들일 경우 오류가 발생할 것을 예상할 수 있다.\n",
    "#### 이 경우에는 encoding = 'cp949' 을 설정해야 오류를 피할 수 있다.\n",
    "\n",
    "#### 결론 : 기본 인코딩에 의존하지 말고 인코딩을 명시하자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " locale.getpreferredencoding() -> cp949\n",
      "                 type(my_file) -> <class '_io.TextIOWrapper'>\n",
      "              my_file.encoding -> cp949\n",
      "           sys.stdout.isatty() -> False\n",
      "           sys.stdout.encoding -> UTF-8\n",
      "            sys.stdin.isatty() -> False\n",
      "            sys.stdin.encoding -> utf-8\n",
      "           sys.stderr.isatty() -> False\n",
      "      sys.getdefaultencoding() -> utf-8\n",
      "   sys.getfilesystemencoding() -> utf-8\n"
     ]
    }
   ],
   "source": [
    "import sys, locale\n",
    "\n",
    "expressions = \"\"\" \n",
    "        locale.getprefererdencoding()\n",
    "        type(my_file)\n",
    "        my_file.encoding\n",
    "        sys.stdout.isatty()\n",
    "        sys.stdout.encoding\n",
    "        sys.stdin.isatty()\n",
    "        sys.stdin.encoding\n",
    "        sys.stderr.isatty()\n",
    "        sys.getdefaultencoding()\n",
    "        sys.getfilesystemencoding()\n",
    "\"\"\"\n",
    "\n",
    "my_file = open('dummy', 'w')\n",
    "\n",
    "for expression in expressions.split() :\n",
    "    value = eval(expression)\n",
    "    print(f\"{expression:>30} -> {str(value)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "café café\n",
      "5 5\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "s1 = 'café'\n",
    "s2 = \"cafe\\u0301\"\n",
    "print(s1,s2)\n",
    "print(len(s1), len(s2))\n",
    "print(s1 == s2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 비유니코드 문자열 정렬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sorted() 사용 :  ['acerola', 'atemoia', 'açaí', 'cajá', 'caju']\n",
      "올바른 정렬 :  ['açaí' 'acerola' 'atemoia' 'cajá' 'caju']\n"
     ]
    }
   ],
   "source": [
    "# 포르투갈어 등 라틴어에서는 갈고리나 악센트가 문자에 붙어 정렬이 비정상적일 수 있다.\n",
    "import numpy as np\n",
    "\n",
    "fruits = ['caju', 'atemoia', 'cajá', 'açaí', 'acerola']\n",
    "order = [3,4,1,2,0]\n",
    "print('sorted() 사용 : ', sorted(fruits))\n",
    "print(\"올바른 정렬 : \", np.array(fruits)[order])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 특수문자가 포함된 문자열을 locale.strxfrm() 함수를 통해 현지어로 바꿀 수있다.\n",
    "#### 그러기 위해선 locale.setlocale(locale.LC_COLLATE, <지역_언어>) 을 호출해야한다.\n",
    "#### 하지만 locale.setlocale은 시스템 전역에 영향을 미치므로 이는 추천하지 않는 방법이다.\n",
    "#### 또한 OS에서 이 설정을 지원해야 한다. 그렇지 않으면 오류가 발생하거나 올바르게 정렬되지 않을 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['açaí', 'acerola', 'atemoia', 'cajá', 'caju']\n"
     ]
    }
   ],
   "source": [
    "import locale\n",
    "locale.setlocale(locale.LC_COLLATE, 'pt_BR.UTF-8')\n",
    "\n",
    "# 윈도우 환경에서는 locale 설정이 지원되고 올바르게 정렬된 것을 확인할 수 있다.\n",
    "print(sorted(fruits, key = locale.strxfrm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 이 문제를 겪고 천재 제임스 토버님께서 라이브러리를 만드셨다.\n",
    "#### 사용법은 간단하다. 그냥 key 에 'sort_key' method 를 주면 된다.   \n",
    "#### 정렬 방식을 커스트마이징 하고 싶다면 Collator()에 직접 만든 대조테이블을 제공하면 된다.\n",
    "#### 기본적으로 라이브러리 내의 [allkeys.txt](https://github.com/jtauber/pyuca)를 사용한다.\n",
    "#### 이는 유니코드 6.3.0 에서 제공하는 [기본 유니코드 대조 요소 테이블](http://bit.ly/1IqAk54)의 사본이다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['açaí', 'acerola', 'atemoia', 'cajá', 'caju']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pyuca \n",
    "coll = pyuca.Collator()\n",
    "print(sorted(fruits, key = coll.sort_key))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 유니코드 데이터 베이스"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 유니코드 데이터베이스에는 코드 포인트를 문자명으로 매핑하는 테이블 뿐만 아니라 메타데이터도 담고 있다.\n",
    "#### unicodedata.numeric()이 재밌는데 문자가 나타내는 숫자를 저장해놓았다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U+0031\t  1   \tre_dig\tisdig\tisnum\t 1.00\tDIGIT ONE\n",
      "U+00bc\t  ¼   \t-\t-\tisnum\t 0.25\tVULGAR FRACTION ONE QUARTER\n",
      "U+00b2\t  ²   \t-\tisdig\tisnum\t 2.00\tSUPERSCRIPT TWO\n",
      "U+0969\t  ३   \tre_dig\tisdig\tisnum\t 3.00\tDEVANAGARI DIGIT THREE\n",
      "U+136b\t  ፫   \t-\tisdig\tisnum\t 3.00\tETHIOPIC DIGIT THREE\n",
      "U+216b\t  Ⅻ   \t-\t-\tisnum\t12.00\tROMAN NUMERAL TWELVE\n",
      "U+2466\t  ⑦   \t-\tisdig\tisnum\t 7.00\tCIRCLED DIGIT SEVEN\n",
      "U+2480\t  ⒀   \t-\t-\tisnum\t13.00\tPARENTHESIZED NUMBER THIRTEEN\n",
      "U+3285\t  ㊅   \t-\t-\tisnum\t 6.00\tCIRCLED IDEOGRAPH SIX\n"
     ]
    }
   ],
   "source": [
    "import unicodedata\n",
    "import re\n",
    "\n",
    "# 모든 유니코드 십진수의 정규표현식\n",
    "re_digit = re.compile(r'\\d')\n",
    "\n",
    "sample = '1\\xbc\\xb2\\u0969\\u136b\\u216b\\u2466\\u2480\\u3285'\n",
    "\n",
    "for char in sample :\n",
    "    decode = hex(ord(char))[2:]\n",
    "    print(f\"U+{decode:0>4}\",\n",
    "          f\"{char:^6}\",\n",
    "          're_dig' if re_digit.match(char) else '-',\n",
    "          'isdig' if char.isdigit() else '-',\n",
    "          'isnum' if char.isnumeric() else '-',\n",
    "          f\"{unicodedata.numeric(char):5.2f}\",\n",
    "          unicodedata.name(char),\n",
    "          sep = '\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 정규표현식\n",
    "### bytes : \\d, \\w 와 같은 패턴은 아스키 문자만 매칭된다.\n",
    "### str   : 아스키 문자 이외에 유니코드 숫자나 문자도 매칭된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text\n",
      "   Ramanujan saw ௧௧௭௨௯ as 1729 = 1³ + 12³ = 9³ + 10³.\n",
      "Numbers\n",
      "   str : ['௧௧௭௨௯', '1729', '1', '12', '9', '10']\n",
      "   bytes : [b'1729', b'1', b'12', b'9', b'10']\n",
      "Words\n",
      "   str : ['Ramanujan', 'saw', '௧௧௭௨௯', 'as', '1729', '1³', '12³', '9³', '10³']\n",
      "   bytes : [b'Ramanujan', b'saw', b'as', b'1729', b'1', b'12', b'9', b'10']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "re_numbers_str = re.compile(r\"\\d+\")\n",
    "re_words_str = re.compile(r\"\\w+\")\n",
    "re_numbers_bytes = re.compile(rb'\\d+')\n",
    "re_words_bytes = re.compile(rb'\\w+')\n",
    "\n",
    "text_str = \"Ramanujan saw \\u0be7\\u0be7\\u0bed\\u0be8\\u0bef as 1729 = 1³ + 12³ = 9³ + 10³.\"\n",
    "\n",
    "text_bytes = text_str.encode('utf-8')\n",
    "\n",
    "print(\"Text\", text_str, sep = '\\n   ')\n",
    "print(\"Numbers\")\n",
    "print(\"   str :\", re_numbers_str.findall(text_str))\n",
    "print(\"   bytes :\", re_numbers_bytes.findall(text_bytes))\n",
    "print(\"Words\")\n",
    "print(\"   str :\", re_words_str.findall(text_str))\n",
    "print(\"   bytes :\", re_words_bytes.findall(text_bytes))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
